{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parag\\Downloads\\beer_price_prediction\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://192.168.1.6:8080\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BaseSellingPrice UserHistory AgeGroup DeviceType OSType ScreenSize  \\\n",
      "0               5.0     Premium    18-24     Mobile    iOS      Large   \n",
      "\n",
      "  CompetitorPricing RegionalDemand CustomerRating PaydayProximity  ...  \\\n",
      "0           Similar           High           High            Near  ...   \n",
      "\n",
      "  ProductMarketingStatus DayOfWeek DemandIndex SpecialOccasion Temperature  \\\n",
      "0                    Low    Friday      Medium            None          22   \n",
      "\n",
      "   WeatherCondition InventoryLevel CityType WeekdayType  DayType  \n",
      "0             Sunny           High    Rural     Weekend  Regular  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Feb/2025 22:09:31] \"POST /invocations HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask,request\n",
    "import flask\n",
    "import threading\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pytz\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from tensorflow.keras.models import Model, load_model\n",
    "from calclulate_price import calculate_dynamic_beer_price\n",
    "import google.generativeai as genai\n",
    "# from googletrans import Translator\n",
    "# import googletrans\n",
    "\n",
    "\n",
    "genai.configure(api_key='')\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)\n",
    "# loaded_model = load_model('beer_model/beer_price_model_v2.keras')\n",
    "# scaler = joblib.load('beer_model/beer_price_scaler_v2.pkl')\n",
    "# feature_names = joblib.load('beer_model/beer_price_feature_names_v2.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def predict_single_entry(model, scaler, feature_names, cat_features, num_features, data_dict):\n",
    "#     \"\"\"\n",
    "#     Predict beer price for a single entry.\n",
    "#     \"\"\"\n",
    "#     df = pd.DataFrame([data_dict])\n",
    "#     df_encoded = pd.get_dummies(df, columns=cat_features, dtype=np.float32)\n",
    "\n",
    "#     for col in feature_names:\n",
    "#         if col not in df_encoded.columns:\n",
    "#             df_encoded[col] = 0\n",
    "\n",
    "#     # Select only numerical features for scaling\n",
    "#     X_num = df_encoded[num_features].values.astype(np.float32)\n",
    "#     X_scaled_num = scaler.transform(X_num)  # Scale numerical features\n",
    "\n",
    "#     # Combine scaled numerical features and one-hot encoded categorical features\n",
    "#     X_cat = df_encoded[[col for col in feature_names if col not in num_features]].values.astype(np.float32)\n",
    "#     X_scaled = np.concatenate([X_scaled_num, X_cat], axis=1)\n",
    "\n",
    "#     prediction = model.predict(X_scaled, verbose=0).flatten()[0]\n",
    "#     return prediction\n",
    "\n",
    "########## FLASK CODE BEGINS ##########\n",
    "\n",
    "app = Flask(__name__)\n",
    "# from flask_cors import CORS\n",
    "# CORS(app)\n",
    "\n",
    "@app.route('/ping', methods=['GET'])\n",
    "def ping():\n",
    "    return flask.Response(response='Successful Ping')\n",
    "\n",
    " \n",
    "\n",
    "@app.route('/invocations', methods=['POST'])\n",
    "def query_generation():\n",
    "    start = datetime.now(ist)\n",
    "    current_timestamp_start = start.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "\n",
    "    beer_data = request.get_json()\n",
    "\n",
    "\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # num_features = ['ProductionCost', 'BrandStrength', 'ABV', 'IBU', 'CustomerRatings', 'ShelfLife', 'Temperature', 'Month']\n",
    "        # cat_features = ['BeerType', 'Packaging', 'Country', 'DemandIndex', 'Import/Local']\n",
    "\n",
    "        # predicted_price = predict_single_entry(loaded_model, scaler, feature_names, cat_features, num_features, beer_data)\n",
    "        df = pd.DataFrame([beer_data])\n",
    "        print(df)\n",
    "        predicted_price=calculate_dynamic_beer_price(df)\n",
    "        schema=f\"\"\" You are a FAQ chatbot which takes base selling price and predicted price of a beer based on several factors provided in context.\n",
    "        Use the context provided {beer_data}, the predicted price is {predicted_price} .\n",
    "        1. You need to provide the reasoning of % price change in base price and predicted price on factors mentioned above.\n",
    "        2. Use html format strictly\n",
    "        Create a 4 bullet pointed short and concise answer for above. Use facts only, do not hallucinate.\n",
    "\n",
    "        Directly provide the answer, do not say i can help with you that, start with heading like Reasoning behind this Price Prediction.\n",
    "        \"\"\"\n",
    "\n",
    "        # messages = [\n",
    "        #             {\"role\": \"system\", \"content\": schema}\n",
    "        # ]\n",
    "\n",
    "        # answer,query_logs = llm(input_sentence,messages)\n",
    "        \n",
    "        model=genai.GenerativeModel('gemini-2.0-flash')\n",
    "        response=model.generate_content(schema)\n",
    "        # print(response.text)\n",
    "        reasoning=response.text\n",
    "        answer=json.dumps({\"predicted_price\":float(predicted_price),\"reasoning\":reasoning})\n",
    "    except Exception as e:\n",
    "        errors = {'Errors':e}\n",
    "        print(errors)\n",
    "        answer=\"Error\"\n",
    "    \n",
    "    \n",
    "    return flask.Response(response=answer, status=200, mimetype='application/json')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port = 8080, threaded = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
