{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7.0\n",
      "Name: BaseSellingPrice, dtype: float64\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def calculate_dynamic_beer_price(df, min_adjustment=-0.15, max_adjustment=0.40, noise_level=0.02):\n",
    "    \"\"\"\n",
    "    Calculates dynamic beer price based on behavioral and situational factors.\n",
    "    \"\"\"\n",
    "    # Behavioral Markups\n",
    "    user_history_markup = {\n",
    "        'New': 0.98, 'Frequent': 1.02, 'Premium': 1.03, 'VIP': 1.04, 'Occasional': 1.00, 'Lapsed': 0.97\n",
    "    }\n",
    "    age_group_markup = {\n",
    "        '18-24': 1.02, '25-34': 1.03, '35-44': 1.02, '45-54': 1.01, '55+': 0.99\n",
    "    }\n",
    "    device_type_markup = {\n",
    "        'Mobile': 1.02, 'Desktop': 1.00, 'Tablet': 1.01, 'Smart TV': 1.00\n",
    "    }\n",
    "    os_type_markup = {\n",
    "        'iOS': 1.03, 'Android': 1.02, 'Windows': 1.00, 'MacOS': 1.01\n",
    "    }\n",
    "    screen_size_markup = {\n",
    "        'Small': 0.98, 'Medium': 1.00, 'Large': 1.02\n",
    "    }\n",
    "    competitor_pricing_markup = {\n",
    "        'Lower': 0.98, 'Similar': 1.00, 'Higher': 1.02\n",
    "    }\n",
    "    regional_demand_markup = {\n",
    "        'Low': 0.98, 'Medium': 1.01, 'High': 1.04\n",
    "    }\n",
    "    customer_rating_markup = {\n",
    "        'Low': 0.97, 'Medium': 1.00, 'High': 1.03\n",
    "    }\n",
    "    payday_proximity_markup = {\n",
    "        'Far': 0.99, 'Near': 1.02\n",
    "    }\n",
    "    tourism_level_markup = {\n",
    "        'Low': 0.98, 'Medium': 1.01, 'High': 1.04\n",
    "    }\n",
    "    product_marketing_status_markup = {\n",
    "        'Low': 0.98, 'Medium': 1.01, 'High': 1.03\n",
    "    }\n",
    "    def get_time_day_markup(hour, day):\n",
    "        time_markup = 0.98 if hour < 12 else (1.00 if hour < 16 else 1.02)\n",
    "        day_markup = {'Monday': 0.98, 'Tuesday': 0.99, 'Wednesday': 1.00, 'Thursday': 1.01, 'Friday': 1.04, 'Saturday': 1.05, 'Sunday': 1.02}\n",
    "        happy_hour_factor = 0.98 if 16 <= hour < 19 else 1.00\n",
    "        return time_markup * day_markup.get(day, 1.00) * happy_hour_factor\n",
    "\n",
    "    demand_markup = {'Very Low': 0.95, 'Low': 0.97, 'Medium': 1.00, 'High': 1.02, 'Very High': 1.04}\n",
    "    event_markup = {'None': 1.00, 'Sports Event': 1.05, 'Festival': 1.04, 'Holiday': 1.04, 'Concert': 1.06}\n",
    "\n",
    "    def get_weather_markup(row):\n",
    "        temp_factor = 1 + (row.get('Temperature', 20) - 20) * 0.005\n",
    "        weather_factors = {'Sunny': 1.02, 'Rainy': 0.98, 'Cloudy': 0.99, 'Snow': 1.02, 'Clear': 1.01}\n",
    "        return temp_factor * weather_factors.get(row.get('WeatherCondition', 'Clear'), 1.00)\n",
    "\n",
    "    inventory_level_markup = {'Low': 1.04, 'Medium': 1.02, 'High': 0.98}\n",
    "    city_type_markup = {'Urban': 1.03, 'Suburban': 1.02, 'Rural': 0.98}\n",
    "    weekday_type_markup = {'Weekday': 1.00, 'Weekend': 1.03}\n",
    "    day_type_markup = {'Regular': 1.00, 'Holiday': 1.03}\n",
    "\n",
    "    base_selling_price=df['BaseSellingPrice']\n",
    "    max_price = base_selling_price * (1 + max_adjustment)\n",
    "    min_price = base_selling_price * (1 + min_adjustment)\n",
    "    \n",
    "    base_price = df['BaseSellingPrice']\n",
    "    base_price *= df['UserHistory'].map(user_history_markup)\n",
    "    base_price *= df['AgeGroup'].map(age_group_markup)\n",
    "    base_price *= df['DeviceType'].map(device_type_markup)\n",
    "    base_price *= df['OSType'].map(os_type_markup)\n",
    "    base_price *= df['ScreenSize'].map(screen_size_markup)\n",
    "    base_price *= df['CompetitorPricing'].map(competitor_pricing_markup)\n",
    "    base_price *= df['RegionalDemand'].map(regional_demand_markup)\n",
    "    base_price *= df['CustomerRating'].map(customer_rating_markup)\n",
    "    base_price *= df['PaydayProximity'].map(payday_proximity_markup)\n",
    "    base_price *= df['TourismLevel'].map(tourism_level_markup)\n",
    "    base_price *= df['ProductMarketingStatus'].map(product_marketing_status_markup)\n",
    "    base_price *= df.apply(lambda x: get_time_day_markup(datetime.now().hour, x['DayOfWeek']), axis=1)\n",
    "    base_price *= df['DemandIndex'].map(demand_markup)\n",
    "    base_price *= df['SpecialOccasion'].map(event_markup)\n",
    "    base_price *= df.apply(get_weather_markup, axis=1)\n",
    "    base_price *= df['InventoryLevel'].map(inventory_level_markup)\n",
    "    base_price *= df['CityType'].map(city_type_markup)\n",
    "    base_price *= df['WeekdayType'].map(weekday_type_markup)\n",
    "    base_price *= df['DayType'].map(day_type_markup)\n",
    "    # noise = np.random.normal(0, noise_level, len(df))\n",
    "    # base_price *= (1 + noise)\n",
    "    price = np.clip(float(base_price.iloc[0]), float(min_price.iloc[0]), float(max_price.iloc[0]))    \n",
    "    return price\n",
    "    \n",
    "example_json = '''[\n",
    "    {\"BaseSellingPrice\": 5.0, \"UserHistory\": \"Frequent\", \"AgeGroup\": \"25-34\", \"DeviceType\": \"Mobile\", \"OSType\": \"iOS\", \"ScreenSize\": \"Large\", \"CompetitorPricing\": \"Similar\", \"RegionalDemand\": \"High\", \"CustomerRating\": \"High\", \"PaydayProximity\": \"Near\", \"TourismLevel\": \"Medium\", \"ProductMarketingStatus\": \"High\", \"DayOfWeek\": \"Friday\", \"DemandIndex\": \"Medium\", \"SpecialOccasion\": \"None\", \"Temperature\": 22, \"WeatherCondition\": \"Sunny\", \"InventoryLevel\": \"Medium\", \"CityType\": \"Urban\", \"WeekdayType\": \"Weekday\", \"DayType\": \"Regular\"}\n",
    "]'''\n",
    "df_example = pd.DataFrame(json.loads(example_json))\n",
    " \n",
    "print(calculate_dynamic_beer_price(df_example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating beer price data...\n",
      "\n",
      "Training Beer Price Prediction Model V2...\n",
      "Epoch 1/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 2.5000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 2.5000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 2.5000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 2.5000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 2.5000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - mae: nan - mse: nan - val_loss: nan - val_mae: nan - val_mse: nan - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import joblib\n",
    "\n",
    "# def generate_dynamic_beer_price_data(n_samples):\n",
    "#     \"\"\"\n",
    "#     Generates independent variables for dynamic beer pricing.\n",
    "#     Returns a DataFrame with relevant features.\n",
    "#     \"\"\"\n",
    "#     data = {\n",
    "#         'UserHistory': np.random.choice(['New', 'Frequent', 'Rare'], n_samples),\n",
    "#         'AgeGroup': np.random.choice(['18-24', '25-34', '35-44', '45-54', '55+'], n_samples),\n",
    "#         'DeviceType': np.random.choice(['Mobile', 'Desktop', 'Tablet'], n_samples),\n",
    "#         'OSType': np.random.choice(['iOS', 'Android', 'Windows', 'MacOS'], n_samples),\n",
    "#         'ScreenSize': np.random.choice(['Small', 'Medium', 'Large'], n_samples),\n",
    "#         'CompetitorPricing': np.random.uniform(5, 15, n_samples),\n",
    "#         'RegionalDemand': np.random.choice(['Low', 'Medium', 'High'], n_samples),\n",
    "#         'CustomerRating': np.random.uniform(1, 5, n_samples),\n",
    "#         'PaydayProximity': np.random.choice(['Far', 'Near']),\n",
    "#         'TourismLevel': np.random.choice(['Low', 'Medium', 'High'], n_samples),\n",
    "#         'ProductMarketingStatus': np.random.choice(['Low', 'Medium', 'High'], n_samples),\n",
    "#         'DayOfWeek': np.random.choice(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], n_samples),\n",
    "#         'DemandIndex': np.random.choice(['Low', 'Medium', 'High'], n_samples),\n",
    "#         'SpecialOccasion': np.random.choice([0, 1], n_samples),\n",
    "#         'WeatherCondition': np.random.choice(['Sunny', 'Rainy', 'Snowy', 'Cloudy'], n_samples),\n",
    "#         'InventoryLevel': np.random.choice(['Low', 'Medium', 'High'], n_samples),\n",
    "#         'CityType': np.random.choice(['Urban', 'Suburban', 'Rural'], n_samples),\n",
    "#         'WeekdayType': np.random.choice(['Weekday', 'Weekend'], n_samples),\n",
    "#         'DayType': np.random.choice(['Holiday', 'Workday', 'Special Event'], n_samples),\n",
    "#         'BaseSellingPrice': np.random.uniform(5, 20, n_samples),\n",
    "#         'Temperature': np.random.uniform(-5, 35, n_samples),\n",
    "#         'PaydayProximity': np.random.choice(['Far', 'Near'], n_samples)\n",
    "\n",
    "#     }\n",
    "#     return pd.DataFrame(data)\n",
    "\n",
    "# def create_improved_model(input_dim, learning_rate=0.0007):\n",
    "#     \"\"\"Create an improved model architecture for beer price prediction\"\"\"\n",
    "#     main_input = Input(shape=(input_dim,), dtype=tf.float32)\n",
    "#     normalized = BatchNormalization()(main_input)\n",
    "#     dense1 = Dense(128, activation='relu')(normalized)\n",
    "#     dense2 = Dense(64, activation='relu')(dense1)\n",
    "#     output = Dense(1)(dense2)\n",
    "#     model = Model(inputs=main_input, outputs=output)\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#                  loss='mse',\n",
    "#                  metrics=['mae', 'mse'])\n",
    "#     return model\n",
    "\n",
    "# # Generate and prepare data\n",
    "# print(\"Generating beer price data...\")\n",
    "# df = generate_dynamic_beer_price_data(10000)\n",
    "\n",
    "# # Define numerical and categorical features\n",
    "# num_features = ['BaseSellingPrice', 'Temperature', 'CompetitorPricing', 'CustomerRating']\n",
    "# cat_features = [\n",
    "#     'UserHistory', 'AgeGroup', 'DeviceType', 'OSType', 'ScreenSize', 'RegionalDemand',\n",
    "#     'PaydayProximity', 'TourismLevel', 'ProductMarketingStatus', 'DayOfWeek', 'DemandIndex',\n",
    "#     'SpecialOccasion', 'WeatherCondition', 'InventoryLevel', 'CityType', 'WeekdayType', 'DayType'\n",
    "# ]\n",
    "\n",
    "# # Encode categorical features\n",
    "# df['DemandIndex'] = df['DemandIndex'].map({'Low': -1, 'Medium': 0, 'High': 1}).astype(np.float32)\n",
    "# df_encoded = pd.get_dummies(df, columns=[col for col in cat_features if col != 'DemandIndex'], dtype=np.float32)\n",
    "\n",
    "# feature_names = [col for col in df_encoded.columns if col not in ['Price']]\n",
    "\n",
    "# # Scale numerical features\n",
    "# scaler = MinMaxScaler()\n",
    "# df_encoded[num_features] = scaler.fit_transform(df_encoded[num_features])\n",
    "\n",
    "# # Calculate target variable: Beer Price\n",
    "# df_encoded['Price'] = calculate_dynamic_beer_price(df)\n",
    "\n",
    "# # Save preprocessing objects\n",
    "# joblib.dump(scaler, 'beer_price_scaler_v2.pkl')\n",
    "# joblib.dump(feature_names, 'beer_price_feature_names_v2.pkl')\n",
    "\n",
    "# # Prepare features and target\n",
    "# X = df_encoded[feature_names].values.astype(np.float32)\n",
    "# y = df_encoded['Price'].values.astype(np.float32)\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Create and train improved model\n",
    "# model = create_improved_model(X_train.shape[1], learning_rate=0.001)\n",
    "\n",
    "# callbacks = [\n",
    "#     EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "#     ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.00001)\n",
    "# ]\n",
    "\n",
    "# # Train model\n",
    "# print(\"\\nTraining Beer Price Prediction Model V2...\")\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_valid, y_valid),\n",
    "#     epochs=200,\n",
    "#     batch_size=64,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # Save model and test data\n",
    "# model.save('beer_price_model_v2.keras')\n",
    "# np.save('X_test_beer_price_v2.npy', X_test)\n",
    "# np.save('y_test_beer_price_v2.npy', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
